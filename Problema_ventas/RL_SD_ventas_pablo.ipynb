{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juancamiloespana/RL_DS/blob/master/RL_SD_ventas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se tiene por objetivo optimizar los parámetros de un modelo de dinámica de sistemas que modela la venta de un único producto. Los parámetros de interes y sus respectivos ragngos de posibles valores son:\n",
        "\n",
        "* `initial_sales_force = (25,75)`\n",
        "* `average_salary = (20000,30000)`\n",
        "* `widget_price = (98,102)`\n",
        "* `exit_rate = (0.15,0.25)`\n",
        "\n",
        "La principal variable de salida es la utilidad total, calculada como la suma de las utilidades en los distntos periodos de tiempo. Sin embargo, hay otras variables que permiten describir el desempeño total del sistema al final de la simulación. Siendo así las variables de resultado son:\n",
        "\n",
        "* `total_revenues`\n",
        "* `size_of_sales_force`\n",
        "* `total_hires`\n",
        "* `total_departures`\n",
        "* `total_widget_sales`\n",
        "\n"
      ],
      "metadata": {
        "id": "_uaXmRdc5OIP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelo de aprendizaje reforzado "
      ],
      "metadata": {
        "id": "7xX6wwKH1KXS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "El modelo formulado considera los siguientes elementos:\n",
        "* un modelo de dinámica de sistema `DSmodel` que con base en los parámetros de entrada calcula las variables de resultado basado en una simulación de un horizonte de tiempo `horizon` y un delta de tiempo `dt`.\n",
        "* Un entorno (`environment`) del que en cada instante del tiempo se puede obtener una observación (`obs`) de su estado actual. \n",
        "* Una observación corresponde a un vector de 9 posiciones que contiene el valor actual de los cuatro parámetros de interes y el valor actual (resultado de correr el modelo de simulación con esos parámetros) para las cinco variables de resultado. \n",
        "> `[ 0 1 0 1 0 17 20]`\n",
        "* Un agente (`agent`) que con base en una observación del estado actual del sistema toma una acción `a` respecto a los parámetros del módelo. El tamaño del espacio de acciones es el doble del número de acciones dado que se considera la posibilidad de incrementar el valor del parámetro (multiplicarlo por 1+δ) o disminuir el valor del parámetro, multiplicarlo por 1-δ). Así por ejemplo, las dos acciones posible para el parámetro `exit_rate` y un $\\delta = 0.01$ se representan como las tuplas: $(exit\\_rate, 0.99)$ y $(exit\\_rate, 1.01)$\n",
        "* La decisión del agente se basa en la predicción realizada por una red neuronal (`net`). Esta red recibe una observación y devuelve la probabilidad de cada una de las acciones\n",
        "\n"
      ],
      "metadata": {
        "id": "MGKTRdj7PKRe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementaremos cada uno de los elementos mencionados, para ello primero instalamos los paquetes requeridos"
      ],
      "metadata": {
        "id": "78jmrOQzRXtk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import namedtuple\n",
        "from collections import OrderedDict\n",
        "import numpy as np\n",
        "import itertools  \n",
        "import plotly.graph_objects as go\n",
        "import random\n",
        "import copy\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "Opiaq0L21MzK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelo de dinámica de sistemas\n",
        "\n",
        "Esta clase implementa el modelo de dinámica de sistemas. Inicializa todos los parámetros y resultados en cero. Se implementa un metodo de inicialización de parámetros `initialise()` que permite definir valores diferentes para los parámetros. El método `run()` ejecuta el modelo y devuleve un diccionario con el valor de las cinco variables de resultado. \n"
      ],
      "metadata": {
        "id": "m3lcA0yC952W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DSmodel:\n",
        "  def __init__(self, horizon, dt):\n",
        "    self.horizon = horizon \n",
        "    self.dt = dt\n",
        "    self.total_time = int(horizon/dt) \n",
        "    self.initial_sales_force = 0 \n",
        "    self.average_salary = 0 \n",
        "    self.widget_price = 0 \n",
        "    self.exit_rate = 0 \n",
        "    # Definición del nivel\n",
        "    self.size_of_sales_force = 0\n",
        "    # Definición de los flujos\n",
        "    self.New_hires = 0\n",
        "    self.Departures = 0\n",
        "    # Definición de las variables auxiliares\n",
        "    self.budgeted_size = 0\n",
        "    self.sales_dep = 0\n",
        "    self.annual_revenues = 0\n",
        "    self.widget_sales = 0\n",
        "    self.effectiveness_widgets = 0\n",
        "    \n",
        "    self.total_revenues = 0\n",
        "    self.total_hires = 0\n",
        "    self.total_departures = 0\n",
        "    self.total_widget_sales = 0\n",
        "\n",
        "    self.dict_results = OrderedDict()\n",
        "    self.dict_results['total_revenues'] = 0\n",
        "    self.dict_results['size_of_sales_force'] = 0\n",
        "    self.dict_results['total_hires'] =  0\n",
        "    self.dict_results['total_departures'] =  0\n",
        "    self.dict_results['total_widget_sales'] =  0\n",
        "                    \n",
        "\n",
        "  def initialise(self,\n",
        "                 initial_sales_force, \n",
        "                 average_salary,\n",
        "                 widget_price,\n",
        "                 exit_rate\n",
        "                 ):\n",
        "    self.initial_sales_force = initial_sales_force \n",
        "    self.average_salary = average_salary \n",
        "    self.widget_price = widget_price \n",
        "    self.exit_rate = exit_rate\n",
        "    # Definición del nivel\n",
        "    self.size_of_sales_force = 0\n",
        "    # Definición de los flujos\n",
        "    self.New_hires = 0\n",
        "    self.Departures = 0\n",
        "    # Definición de las variables auxiliares\n",
        "    self.budgeted_size = 0\n",
        "    self.sales_dep = 0\n",
        "    self.annual_revenues = 0\n",
        "    self.widget_sales = 0\n",
        "    self.effectiveness_widgets = 0 \n",
        "\n",
        "    self.total_revenues = 0\n",
        "    self.total_hires = 0\n",
        "    self.total_departures = 0\n",
        "    self.total_widget_sales = 0\n",
        "\n",
        "    self.dict_results = OrderedDict()\n",
        "    self.dict_results['total_revenues'] = 0\n",
        "    self.dict_results['size_of_sales_force'] = 0\n",
        "    self.dict_results['total_hires'] =  0\n",
        "    self.dict_results['total_departures'] =  0\n",
        "    self.dict_results['total_widget_sales'] =  0\n",
        "\n",
        "  def run(self):\n",
        "    for i in range(self.total_time):\n",
        "        if i == 0:\n",
        "            self.size_of_sales_force = self.initial_sales_force\n",
        "        else:\n",
        "            self.size_of_sales_force += (self.New_hires - self.Departures) * self.dt\n",
        "        \n",
        "        # Caclula effectiveness_widgets\n",
        "        if 0 <= self.size_of_sales_force < 600:\n",
        "            self.effectiveness_widgets = 2\n",
        "        if 600 <= self.size_of_sales_force < 800:\n",
        "            self.effectiveness_widgets = 2+((1.8-2)*(self.size_of_sales_force-600)/(800-600))\n",
        "        if 800 <= self.size_of_sales_force < 1000:\n",
        "            self.effectiveness_widgets = 1.8+((1.6-1.8)*(self.size_of_sales_force-800)/(1000-800))\n",
        "        if 1000 <= self.size_of_sales_force < 1200:\n",
        "            self.effectiveness_widgets = 1.6+((0.8-1.6)*(self.size_of_sales_force-1000)/(1200-1000))\n",
        "        else:\n",
        "            self.effectiveness_widgets = 0.8+((0.4-0.8)*(self.size_of_sales_force-1200)/(1400-1200))\n",
        "\n",
        "        self.widget_sales = self.size_of_sales_force * self.effectiveness_widgets * 365\n",
        "        self.annual_revenues = self.widget_sales * self.widget_price / 1000000        \n",
        "        self.sales_dep = self.annual_revenues * 0.5\n",
        "        self.budgeted_size = self.sales_dep * 1000000 / self.average_salary\n",
        "        self.New_hires = self.budgeted_size - self.size_of_sales_force\n",
        "        self.Departures = self.size_of_sales_force * self.exit_rate    \n",
        "\n",
        "        self.total_revenues += self.annual_revenues\n",
        "        self.total_hires += self.New_hires\n",
        "        self.total_departures += self.Departures\n",
        "        self.total_widget_sales += self.widget_sales \n",
        "\n",
        "    self.dict_results['total_revenues'] = self.total_revenues\n",
        "    self.dict_results['size_of_sales_force'] = self.size_of_sales_force\n",
        "    self.dict_results['total_hires'] =  self.total_hires\n",
        "    self.dict_results['total_departures'] =  self.total_departures\n",
        "    self.dict_results['total_widget_sales'] =  self.total_widget_sales\n",
        "\n",
        "    return self.dict_results\n",
        "    \n"
      ],
      "metadata": {
        "id": "2hMpH5-Ds6qJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuación se crea un modelo y se ejecuta con datos de prueba para los parámetros\n",
        "\n"
      ],
      "metadata": {
        "id": "1Ff32udx_sUf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = DSmodel(20, 0.1)\n",
        "model.initialise(initial_sales_force = 30,\n",
        "                average_salary = 25000,\n",
        "                widget_price = 100,\n",
        "                exit_rate = 0.20)\n",
        "results = model.run()\n",
        "results"
      ],
      "metadata": {
        "id": "jXvcUrZD_1_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Red neuronal para predecir acción "
      ],
      "metadata": {
        "id": "vzZz1qNf1CwD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La red considera una entrada de observaciones, una función `reLU` y un número `hidden_size` especificado de capas ocultas. La salida debe ser psoteriormente pasada a través de una función `Softmax()` para convertirla en las probabilidades de cada acción"
      ],
      "metadata": {
        "id": "IqL7C4xzBDj3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self, obs_size, hidden_size, n_actions):\n",
        "        super(Net, self).__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(obs_size, hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_size, n_actions)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)"
      ],
      "metadata": {
        "id": "aQAXBA6b4i97"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Probemos la red con una observación fictica"
      ],
      "metadata": {
        "id": "f1EP85-eSE2b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clase `environment`"
      ],
      "metadata": {
        "id": "a_EnZ4XnTiwD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class environment:\n",
        "  '''    \n",
        "    Attributes:\n",
        "    \n",
        "\n",
        "  '''\n",
        "  def __init__(self, \n",
        "               list_param,\n",
        "               list_results,\n",
        "               parm_ranges,\n",
        "               ds_model, \n",
        "               n_iter = 1, \n",
        "               delta = 0.01 ):     \n",
        "    self.list_param = list_param # list of parameters' names\n",
        "    self.list_results = list_results # list of result variables' names\n",
        "    self.dict_max_results = {key:0 for key in self.list_results}\n",
        "    self.parm_ranges = parm_ranges # dictionary with the feasible range of each parameter\n",
        "    self.ds_model = ds_model # Dinamic system model\n",
        "    self.dict_obs = OrderedDict() # dictionary with the observation variables \\\n",
        "                                  # (parameters + result variables)      \n",
        "    self.iter = n_iter # number of parameters changes in the episode \n",
        "    self.moves = 0 # counter of changes\n",
        "    self.iter_max_revenue = 0 # iteration in which the maximum revenue takes place\n",
        "    self.delta = delta # change in the parameter value\n",
        "    # creates the action space\n",
        "    #f1 = lambda x: (x, 1-self.delta)\n",
        "    #f2 = lambda x: (x, 1+self.delta)  \n",
        "    #self.action_space = [f(x) for x in list(self.parm_ranges.keys()) for f in (f1,f2)]\n",
        "    self.action_space = list(itertools.product(list(self.parm_ranges.keys()), \\\n",
        "                               [1-self.delta, 1+self.delta]))\n",
        "    # initialize parameters in a random value within the feasible ranges\n",
        "    self.initialise_param()\n",
        "    # intialize result variables to 0\n",
        "    for result in self.list_results:        \n",
        "      self.dict_obs[result] = 0\n",
        "  \n",
        "\n",
        "  def initialise_param(self):\n",
        "    ''' initialize parameters in a random value within the feasible ranges'''\n",
        "    for param in self.list_param:\n",
        "      self.dict_obs[param] = round(random.uniform(self.parm_ranges[param][0], \\\n",
        "                                                   self.parm_ranges[param][1]), 2)\n",
        "    \n",
        " \n",
        "  def step(self, a):\n",
        "    \"\"\" Takes an action and updates the environment. \"\"\"\n",
        "    is_done = False\n",
        "    action = self.action_space[a]\n",
        "    param_bu = self.dict_obs[action[0]] # back up of the param value\n",
        "    param_new = self.dict_obs[action[0]] * action[1] # new value of the parameter\n",
        "    if param_new < self.parm_ranges[action[0]][0] or param_new > self.parm_ranges[action[0]][1]:\n",
        "      # if the action is not feasible look rendmly for a fesible action \n",
        "      while True:\n",
        "        action_rnd = random.choices(self.action_space)[0]\n",
        "        param_test = self.dict_obs[action_rnd[0]] * action_rnd[1]\n",
        "        if param_test >= self.parm_ranges[action_rnd[0]][0] and param_test <= self.parm_ranges[action_rnd[0]][1]:\n",
        "          action = action_rnd\n",
        "          break\n",
        "    self.dict_obs[action[0]] *= action[1] #update the value of the parameter\n",
        "    # initialise and run the DS model\n",
        "    self.ds_model.initialise(self.dict_obs['initial_sales_force'],\n",
        "                                self.dict_obs['average_salary'],\n",
        "                                self.dict_obs['widget_price'],\n",
        "                                self.dict_obs['exit_rate'])    \n",
        "    results = self.ds_model.run()\n",
        "    # Update observation\n",
        "    for key, value in results.items():\n",
        "      self.dict_obs[key] = value\n",
        "\n",
        "    # update maximum results \n",
        "    for key in self.list_results:\n",
        "      if self.dict_obs[key] > self.dict_max_results[key]:\n",
        "        self.dict_max_results[key] = self.dict_obs[key]\n",
        "        # keep track of the iteration in which the best revenue was reached \n",
        "        if key == 'total_revenues':\n",
        "          self.iter_max_revenue = self.moves\n",
        "\n",
        "    self.moves += 1 # update the moves counter \n",
        "    # check if the maximun number of moves it reached \n",
        "    if self.moves >= self.iter:\n",
        "      is_done = True\n",
        "    return is_done\n",
        "\n",
        "  def getObs(self):\n",
        "    ''' Gets the values of the dictionary of observation '''\n",
        "    return list(self.dict_obs.values())\n",
        "\n",
        "  def getScaledObs(self):\n",
        "    obs_dict = copy.deepcopy(self.dict_obs)\n",
        "    for key in list(self.parm_ranges.keys()):\n",
        "      obs_dict[key] = (obs_dict[key] - self.parm_ranges[key][0])/ \\\n",
        "                 (self.parm_ranges[key][1]-self.parm_ranges[key][0])   \n",
        "    for key in  self.list_results:\n",
        "      if self.dict_max_results[key] != 0:\n",
        "        obs_dict[key] = obs_dict[key]/self.dict_max_results[key]\n",
        "\n",
        "    return list(obs_dict.values())\n",
        "\n",
        "  def reset(self):\n",
        "    \"\"\" Resets results while keeping settings\"\"\"\n",
        "    self.dict_obs = OrderedDict()\n",
        "    self.initialise_param()\n",
        "    for result in self.list_results:        \n",
        "      self.dict_obs[result] = 0\n",
        "    self.dict_max_results = {key:0 for key in self.list_results}\n",
        "    \n",
        "    self.moves = 0\n",
        "    self.max_revenue = 0\n",
        "    self.iter_max_revenue = 0"
      ],
      "metadata": {
        "id": "kvsx9YG9JDp1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clase `agent`"
      ],
      "metadata": {
        "id": "z1ThOihYVpkD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class agent:\n",
        "  '''    \n",
        "    Attributes:\n",
        "    sm (Softmax): softmax operator \n",
        "    eps (real [0,1]): controls diversity\n",
        "\n",
        "  '''\n",
        "  def __init__(self, sm, eps):    \n",
        "    self.action = (-99, None) # Define null action\n",
        "    self.sm = sm    \n",
        "    self.eps = eps\n",
        "\n",
        "\n",
        "  def choose_action(self, env, net):\n",
        "    '''Obtains and observation from the environment and chooses and \n",
        "    action based on the probabilities given for a neural network'''    \n",
        "    p = np.random.rand() # Generate random number\n",
        "    if p < self.eps:\n",
        "      # Randomly select an action\n",
        "      self.action = np.random.choice(len(env.action_space))\n",
        "    else:\n",
        "      # Take greedy action chosing the one with highest probability\n",
        "      obs = env.getObs()\n",
        "      #print(obs)\n",
        "      obs_v = torch.FloatTensor([obs])\n",
        "      act_probs_v = self.sm(net(obs_v))\n",
        "      act_probs = act_probs_v.data.numpy()[0]      \n",
        "      self.action = np.random.choice(len(act_probs), p=act_probs)  \n",
        "\n",
        "    \n",
        "    return self.action\n",
        "\n"
      ],
      "metadata": {
        "id": "eYPK4OaETMVz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Iteración en batches"
      ],
      "metadata": {
        "id": "vpQa0ZOxWvj5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# usa namedtuples para guardar los pasos de cada episodio y los episodios \n",
        "EpisodeStep = namedtuple('EpisodeStep', field_names=['observation', 'action'])\n",
        "Episode = namedtuple('Episode', field_names=['reward', 'steps'])\n",
        "all_revenues = []\n",
        "\n",
        "\n",
        "def iterate_batches(env, agent, net, batch_size):\n",
        "  '''Generate batches of the parameter tunning solutions. \n",
        "     Each solution consist of steps = [observation, actions] taken to solve the \n",
        "     problem. The steps represents the iterative modification of the parameters'\n",
        "     values. The batch collects several solutions (batch_size) '''  \n",
        "  batch = []\n",
        "  episode_reward = 0.0\n",
        "  episode_steps = []  \n",
        "  sm = nn.Softmax(dim=1)\n",
        "  env.reset()\n",
        "\n",
        "  # Repeat until enough solutions are built\n",
        "  while True:\n",
        "    a = agent.choose_action(env, net)     \n",
        "    is_done = env.step(a)\n",
        "    #obs = env.getObs()\n",
        "    obs = env.getScaledObs()\n",
        "    step = EpisodeStep(observation=obs, action=a)\n",
        "    episode_steps.append(step) \n",
        "    all_revenues.append(env.dict_obs['total_revenues'])\n",
        "    # if a solutions is complete, it reset the environment to start a new solution   \n",
        "    if is_done:\n",
        "      # keeeps the steps only until the iteration in which \n",
        "      # the max revvene was reached\n",
        "      episode_steps = episode_steps[0:env.iter_max_revenue+1]\n",
        "      e = Episode(reward=env.dict_max_results['total_revenues'], steps=episode_steps)\n",
        "      batch.append(e)\n",
        "      env.reset()\n",
        "      episode_steps = []\n",
        "      #all_revenues.append(env.dict_obs['total_revenues'])\n",
        "      # If enough solutions are generated it returns the batch\n",
        "      if len(batch) == batch_size:        \n",
        "        yield batch\n",
        "        batch = []"
      ],
      "metadata": {
        "id": "rn_t-M8uv1I1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Selecciona las mejores soluciones "
      ],
      "metadata": {
        "id": "FGrynS1fZCfR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Escoge las mejores soluciones de un batch y extrae las observaciones y la acción que el agente tomó en ellas"
      ],
      "metadata": {
        "id": "mBZ2eKZsZIQI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_batch(batch, percentile):\n",
        "    '''Selects the best solutions given a percentile  ''' \n",
        "    rewards = list(map(lambda s: s.reward, batch))\n",
        "    reward_bound = np.percentile(rewards, percentile)\n",
        "    position_best = np.argmax(rewards)\n",
        "    reward_max = rewards[position_best]    \n",
        "\n",
        "    train_obs = []\n",
        "    train_act = []\n",
        "    for reward, steps in batch:\n",
        "        if reward < reward_bound:\n",
        "            continue\n",
        "        train_obs.extend(map(lambda step: step.observation, steps))\n",
        "        train_act.extend(map(lambda step: step.action, steps))\n",
        "    train_obs_v = torch.FloatTensor(train_obs)\n",
        "    train_act_v = torch.LongTensor(train_act)\n",
        "    \n",
        "    return train_obs_v, train_act_v, reward_bound, reward_max"
      ],
      "metadata": {
        "id": "zXMhTuR5TeRw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experimentación"
      ],
      "metadata": {
        "id": "VXl28KpBawNS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Búsqueda aleatoria\n",
        "\n",
        "Una primera forma de resolver el problema sería mediante búsqueda aletoria. Es decir, corriendo muchas veces el modelo de dinámica de sistema con valores aletarorios de los parámetros. "
      ],
      "metadata": {
        "id": "zRP4h8A6LcNX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_dict = {}\n",
        "param_dict['initial_sales_force'] = [-99, ((10,100))]\n",
        "param_dict['average_salary'] = [-99, (10000,50000)]\n",
        "param_dict['widget_price'] = [-99, (50,100)]\n",
        "param_dict['exit_rate'] = [-99, (0.1,0.5)]\n",
        "horizon = 20\n",
        "dt = 0.1\n",
        "incunbent_hist =[]\n",
        "incunbent = 0\n",
        "iter_hist = []\n",
        "repetitions = 20000 # number of repetitions\n",
        "\n",
        "# Creates the moel\n",
        "ds_model = DSmodel(horizon, dt)\n",
        "\n",
        "def initialise_parameters(param_dict):\n",
        "  ''' initialize parameters randomly '''\n",
        "  for param in list(param_dict.keys()):\n",
        "      param_dict[param][0] = round(random.uniform(param_dict[param][1][0], \\\n",
        "                                               param_dict[param][1][1]), 2)\n",
        "      \n",
        "\n",
        "for i in range(repetitions):\n",
        "  initialise_parameters(param_dict)\n",
        "  ds_model.initialise(param_dict['initial_sales_force'][0],\n",
        "                      param_dict['average_salary'][0],\n",
        "                      param_dict['widget_price'][0],\n",
        "                      param_dict['exit_rate'][0])\n",
        "      \n",
        "  results = ds_model.run()\n",
        "  results\n",
        "  if results['total_revenues'] > incunbent:\n",
        "    incunbent = results['total_revenues']\n",
        "  incunbent_hist.append(incunbent)\n",
        "  iter_hist.append(results['total_revenues'])\n",
        "\n",
        "\n",
        "# Print graph\n",
        "fig = go.Figure()\n",
        "x = list(range(repetitions))\n",
        "fig.add_trace(go.Scatter(x = x, y = incunbent_hist, name= \"incumbent\"))\n",
        "fig.add_trace(go.Scatter(x = x, y = iter_hist, name= \"best_episode\")) \n",
        "fig.show()"
      ],
      "metadata": {
        "id": "CL4Zq5oSMNyX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Aprendizaje reforzado"
      ],
      "metadata": {
        "id": "DdTI-qzcNlxX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "HIDDEN_SIZE = 128\n",
        "BATCH_SIZE = 20\n",
        "PERCENTILE = 70\n",
        "N_EPOCH = 10\n",
        "EPSILON = 0.01\n",
        "n_iter = 100 #iterations within each episode\n",
        "horizon = 20\n",
        "dt = 0.1\n",
        "delta = 0.05 # percentage in which the parameter is changed\n",
        "\n",
        "parm_ranges = OrderedDict()\n",
        "parm_ranges['initial_sales_force'] = (10,100)\n",
        "parm_ranges['average_salary'] = (10000,50000)\n",
        "parm_ranges['widget_price'] = (50,100)\n",
        "parm_ranges['exit_rate'] = (0.1,0.5)\n",
        "\n",
        "list_param = list(parm_ranges.keys())\n",
        "list_results = ['total_revenues', 'size_of_sales_force',\\\n",
        "                    'total_hires', 'total_departures', 'total_widget_sales']\n",
        "observacion_list = list_param + list_results \n",
        "\n",
        "# Lists to save the observed solutions\n",
        "incunbent_hist =[0]\n",
        "incunbent = 0\n",
        "best_list = [0]\n",
        "all_revenues = []\n",
        "\n",
        "# Create neural network \n",
        "net = Net(len(observacion_list), HIDDEN_SIZE, 2*len(list_param))\n",
        "objective = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(params=net.parameters(), lr=0.01)\n",
        "sm = nn.Softmax(dim=1)\n",
        "# Create  agent and environment\n",
        "ds_model = DSmodel(horizon, dt)\n",
        "# Create  agent and environment\n",
        "env = environment(list_param, list_results, parm_ranges, ds_model, n_iter, delta)\n",
        "#print(env.action_space)\n",
        "ag = agent(sm, EPSILON)\n",
        "\n",
        "\n",
        "\n",
        "# Iterate over batches. Each time a batch is created the neural network is\n",
        "# updated\n",
        "for epoch, batch in enumerate(iterate_batches(env, ag, net, BATCH_SIZE)):\n",
        "  \n",
        "  print('epoch_no', epoch, len(all_revenues))  \n",
        "  # Filters the batch\n",
        "  obs_v, acts_v, reward_b, reward_m = filter_batch(batch, PERCENTILE)\n",
        "  \n",
        "  # Updates the incumbent (best solution)\n",
        "  if reward_m > incunbent:\n",
        "    incunbent = reward_m\n",
        "  incunbent_hist.append(incunbent)\n",
        "  best_list.append(reward_m)\n",
        "\n",
        "  # Update network\n",
        "  optimizer.zero_grad()\n",
        "  action_scores_v = net(obs_v)\n",
        "  loss_v = objective(action_scores_v, acts_v)\n",
        "  loss_v.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  # stops if the number of episodes is reached\n",
        "  if epoch >= N_EPOCH:\n",
        "    break\n"
      ],
      "metadata": {
        "id": "4oJQLHuOV45D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imprimamos la forma como evluciona la solución con respecto a la mejor solución de cada una de las epocas o batches"
      ],
      "metadata": {
        "id": "54SH6Klka2lB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = go.Figure()\n",
        "x = list(range(N_EPOCH))\n",
        "fig.add_trace(go.Scatter(x = x, y = incunbent_hist, name= \"incumbent\"))\n",
        "fig.add_trace(go.Scatter(x = x, y = best_list, name= \"best_episode\"))\n",
        " \n",
        "fig.show()"
      ],
      "metadata": {
        "id": "rQM0dZkqY4tP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "veamos ahora el detalle de cada una de las soluciones evaluadas por el algoritmo\n"
      ],
      "metadata": {
        "id": "8BRP8Fq3WlvO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = go.Figure()\n",
        "x = list(range(len(all_revenues)))\n",
        "fig.add_trace(go.Scatter(x = x, y = all_revenues, name= \"revenue\"))\n",
        " \n",
        "fig.show()"
      ],
      "metadata": {
        "id": "0IS_lMv-WwZn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
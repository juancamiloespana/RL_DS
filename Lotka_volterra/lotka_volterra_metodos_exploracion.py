# -*- coding: utf-8 -*-
"""MODELO LOTKA-VOLTERRA

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lfjJaFVcWtmrlqvL0h6b8E2vAjvjVeXk
"""

# Importar libreria para calcular la media
import numpy as np
# Importar los graficos
import matplotlib.pyplot as plt

class LotkaVolterraModel:
    def __init__(self, alpha, beta, delta, gamma, initial_rabbits=100, initial_wolves=25, dt=0.01, total_time=40000):
        self.alpha = alpha
        self.beta = beta
        self.delta = delta
        self.gamma = gamma
        self.initial_rabbits = initial_rabbits
        self.initial_wolves = initial_wolves
        self.dt = dt
        self.total_time = int(total_time)
        self.L = [0]
        self.R = [self.initial_rabbits]
        self.W = [self.initial_wolves]

    def simulate(self):

        for i in range(self.total_time):

            if i == 0:
                wolves = self.initial_wolves
                rabbits = self.initial_rabbits
            else:
                wolves += (wolves_birth - wolves_death) * self.dt
                rabbits += (rabbits_birth - rabbits_death)* self.dt

            wolves_birth = self.alpha * (rabbits * wolves)
            wolves_death = self.beta * wolves

            rabbits_birth = self.delta * rabbits
            rabbits_death = self.gamma * (rabbits * wolves)

            self.L.append(wolves)
            self.R.append(rabbits)
            self.W.append(wolves)

        return np.mean(self.L),  np.mean(self.R)

    def plot_simulation(self):
        time_points = np.linspace(0, self.total_time, len(self.R))
        plt.plot(time_points, self.R, label='Rabbits')
        plt.plot(time_points, self.W, label='Wolves')
        plt.xlabel('Time')
        plt.ylabel('Population')
        plt.title('Lotka-Volterra Simulation')
        plt.legend()
        plt.show()

    def plot_simulation_fase(self):
        time_points = np.linspace(0, self.total_time, len(self.R))
        plt.plot(self.W, self.R, label='Wolves vs Rabbits')
        plt.xlabel('Wolves Population')
        plt.ylabel('Rabbits Population')
        plt.title('Lotka-Volterra Simulation')
        plt.legend()
        plt.show()

# Example usage:
parameters = [0.002, 0.04, 0.1, 0.0025]
lotka_volterra_instance = LotkaVolterraModel(*parameters)
result = lotka_volterra_instance.simulate()
print(f"Average wolves over time: {result}")

# Grafico
lotka_volterra_instance.plot_simulation()
lotka_volterra_instance.plot_simulation_fase()

"""# **e-GREEDY**"""

# Se importa el modelo de Lotka Volterra
#from LotkaVolterra_JSJ import LotkaVolterraModel
# Importar librería para la media
from tkinter import Y
# Se importa paquete matematico numpy
import numpy as np
# Importamos librería genera números aleatorios
import random
# Importamos la libreria de graficas
import matplotlib.pyplot as plt

###para contador de iteraciones
import seaborn as sns
import pandas as pd

# Programación de funciones a usar

# Función para verificar si se violan los rangos de factibilidad de los parámetros a optimizar
def Cumple_Limites(p, l):

    suma = [0]*len(p)

    # Si algún parámetro se sale de los límites se devuelve verdadero
    for i in range(len(p)):

        if p[i] < l[i][0] or p[i] > l[i][1]:
            suma[i]=1

    if sum(suma) > 0:
        return False
    else:
        return True

# Inicio del algoritmo K-Armed bandid para optimizar parámetros del modelo de dinámica de sistemas

E = 0.1 # Parametro de exploracion
fac = [-0.1, -0.05, -0.01, 0, 0.01, 0.05, 0.1] # Posibles cambios que pueden tenre los parámetros
P = [0.002, 0.04, 0.1, 0.0025] # Valor inicial de los parametros
Lim = [[0.0015,0.0025],[0.03,0.05],[0.05,0.15],[0.002,0.003]] # Rango de factibilidad de los parámetros
A = len(fac) # Número de acciones posibles
Q = np.zeros((A,A,A,A)) # Definición de la matriz Q del método K-Armed Bandid
Dim = Q.ndim # Dimensiones
Runs = 3000 # Corridas

lotka_volterra_instance = LotkaVolterraModel(*P)
R_inicial, rabbit_inicial = lotka_volterra_instance.simulate() # Solución inicial del modelo de dinámica de sistemas

# Impresión de parámetros iniciales y solución inicial
print("Parametros iniciales = ", P)
print("Recompensa inicial =", round(R_inicial,5))
print("Rabbits inicial =", round(rabbit_inicial,5))
# Creacion de vector para graficar el retorno
y = [0]
y[0] = R_inicial

# Proceso de explorar - explotar
corrida=[]
data_acum=[]

n_episodios = 3

for j in range(n_episodios):

    P = [0.002, 0.04, 0.1, 0.0025] # Valor inicial de los parametros
    Lim = [[0.0015,0.0025],[0.03,0.05],[0.05,0.15],[0.002,0.003]] # Rango de factibilidad de los parámetros
    A = len(fac) # Número de acciones posibles
    Q = np.zeros((A,A,A,A)) # Definición de la matriz Q del método K-Armed Bandid                              # CAMBIAR ESOS CEROS POR VALORES ALTOOOOS
                                                                                                               # CREAR UNA NUEVA MATRIZ CON LA ECUACION DE UCB
    Dim = Q.ndim # Dimensiones
    Runs = 2400 # Corridas

    for i in range(Runs):

        P_previo = list(P) # Guardo el valor de P previo
        lotka_volterra_instance = LotkaVolterraModel(*P_previo)
        R_previo, rabbits_previo = lotka_volterra_instance.simulate()

        # Se grafica las ganancias
        y.append(R_previo)

        if E < random.random():                                                                                 # HACERLO COMPLETAMENTE GREEDY (DE Q EN EL OTRO CASO DE LA UCB)
            policy = "Max"
            # Opcion explotar
            max_val = np.amax(Q) # Identifico el máximo valor
            result = np.where(Q == max_val) # Encuentro la posición del máximo valor
            I, J, K, L = [result[i][0] for i in range(Dim)] # Guardo la posición del máximo valor

        else:
            policy = "Rand"
            # Proceso de exploracion
            idxs = [0] * Dim
            I, J, K, L = [random.randint(0, A-1) for items in idxs] # Genero una posición aleatoria

        # Asigno un nuevo P de acuerdo a la posición elegida
        P[0] = P[0] * (1+fac[I])
        P[1] = P[1] * (1+fac[J])
        P[2] = P[2] * (1+fac[K])
        P[3] = P[3] * (1+fac[L])

        # Verifico que esta nueva solución P no viole los límites de factibilidad
        if Cumple_Limites(P, Lim) == True:
            lim_cump = "N"
            # Si sí es una solución factible calculo su recompensa y guardo esta posición
            lotka_volterra_instance = LotkaVolterraModel(*P)
            R_actual, rabbits_actual = lotka_volterra_instance.simulate()

            Q[I][J][K][L] += ((R_actual - R_previo) / R_previo)
            # Verifico que la nueva solución sea mejor que la mejor solución anterior, sino, me quedo con la solución mejor.
            if R_previo >= R_actual:
                P = P_previo
        else:
            lim_cump = "S"
            # A una solución que no satisfaga la factibilidad le asigno la penalidad
            Q[I][J][K][L] += -100
            P = P_previo

        corrida = [j] + [R_previo] + [R_actual] + [rabbits_previo] + [rabbits_actual] + P_previo + [fac[I]] + [fac[J]] + [fac[K]] + [fac[L]] + P + [policy] + [lim_cump]
        data_acum.append(corrida)

data_acum = pd.DataFrame(data_acum, columns=['Episodio', 'R_actual', 'R_previo', 'rabbits_previo', 'rabbits_acutal', 'P1_p', 'P2_p', 'P3_p', 'P4_p', 'A1', 'A2', 'A3', 'A4', 'P1_a', 'P2_a', 'P3_a', 'P4_a', 'Policy', 'cumple_lim'])

data_acum.to_csv('datos_egreedy_lotka_volterra.csv')

sns.scatterplot(y='R_actual', x='P1_p', data=data_acum)

# Impresion de los resultados finales
print("Parametros finales = ", P)
lotka_volterra_instance = LotkaVolterraModel(*P)
print("Recompensa final =", lotka_volterra_instance.simulate())

# Generacion de graficos
# x axis values
x = list(range(0, Runs + 1))
# Grilla y ejes
plt.grid(True)
plt.title('Optimización de modelo DS con K-Armed Bandid algoritmo')
plt.xlabel('Iteraciones del método')
plt.ylabel('Valor variable objetivo')
plt.figure(figsize=(10, 6))
plt.text(481, 50, f'Soluciones: inicial= {round(y[0],2)}, final = {round(y[Runs-1],2)}')
plt.text(481, 45, f'% Ganancia = {round((y[Runs-1] - y[0]) / y[0], 2)}')
# plotting the points
plt.plot(x, y)
# function to show the plot
plt.show()

"""# **VALORES OPTIMISTAS**"""

# Se importa el modelo de Lotka Volterra
#from LotkaVolterra_JSJ import LotkaVolterraModel
# Importar librería para la media
from tkinter import Y
# Se importa paquete matematico numpy
import numpy as np
# Importamos librería genera números aleatorios
import random
# Importamos la libreria de graficas
import matplotlib.pyplot as plt

###para contador de iteraciones
import seaborn as sns
import pandas as pd

# Programación de funciones a usar

# Función para verificar si se violan los rangos de factibilidad de los parámetros a optimizar
def Cumple_Limites(p, l):

    suma = [0]*len(p)

    # Si algún parámetro se sale de los límites se devuelve verdadero
    for i in range(len(p)):

        if p[i] < l[i][0] or p[i] > l[i][1]:
            suma[i]=1

    if sum(suma) > 0:
        return False
    else:
        return True

# Inicio del algoritmo K-Armed bandid para optimizar parámetros del modelo de dinámica de sistemas

E = 0.1 # Parametro de exploracion
fac = [-0.1, -0.05, -0.01, 0, 0.01, 0.05, 0.1] # Posibles cambios que pueden tenre los parámetros
P = [0.002, 0.04, 0.1, 0.0025] # Valor inicial de los parametros
Lim = [[0.0015,0.0025],[0.03,0.05],[0.05,0.15],[0.002,0.003]] # Rango de factibilidad de los parámetros
A = len(fac) # Número de acciones posibles
Q = np.zeros((A,A,A,A)) # Definición de la matriz Q del método K-Armed Bandid
Dim = Q.ndim # Dimensiones
Runs = 3000 # Corridas

lotka_volterra_instance = LotkaVolterraModel(*P)
R_inicial, rabbit_inicial = lotka_volterra_instance.simulate() # Solución inicial del modelo de dinámica de sistemas

# Impresión de parámetros iniciales y solución inicial
print("Parametros iniciales = ", P)
print("Recompensa inicial =", round(R_inicial,5))
print("Rabbits inicial =", round(rabbit_inicial,5))
# Creacion de vector para graficar el retorno
y = [0]
y[0] = R_inicial

# Proceso de explorar - explotar
corrida=[]
data_acum=[]

n_episodios = 1

for j in range(n_episodios):

    P = [0.002, 0.04, 0.1, 0.0025] # Valor inicial de los parametros
    Lim = [[0.0015,0.0025],[0.03,0.05],[0.05,0.15],[0.002,0.003]] # Rango de factibilidad de los parámetros
    A = len(fac) # Número de acciones posibles
    Q = np.full((A, A, A, A), 150)                                                                                      #CAMBIAR EL VALOR DE SER NECESARIO
    Dim = Q.ndim # Dimensiones
    Runs = 2400 # Corridas

    for i in range(Runs):

        P_previo = list(P) # Guardo el valor de P previo
        lotka_volterra_instance = LotkaVolterraModel(*P_previo)
        R_previo, rabbits_previo = lotka_volterra_instance.simulate()

        # Se grafica las ganancias
        y.append(R_previo)

        # Opcion explotar
        max_val = np.amax(Q) # Identifico el máximo valor
        result = np.where(Q == max_val) # Encuentro la posición del máximo valor
        I, J, K, L = [result[i][0] for i in range(Dim)] # Guardo la posición del máximo valor

        # Asigno un nuevo P de acuerdo a la posición elegida
        P[0] = P[0] * (1+fac[I])
        P[1] = P[1] * (1+fac[J])
        P[2] = P[2] * (1+fac[K])
        P[3] = P[3] * (1+fac[L])

        # Verifico que esta nueva solución P no viole los límites de factibilidad
        if Cumple_Limites(P, Lim) == True:
            lim_cump = "N"
            # Si sí es una solución factible calculo su recompensa y guardo esta posición
            lotka_volterra_instance = LotkaVolterraModel(*P)
            R_actual, rabbits_actual = lotka_volterra_instance.simulate()

            Q[I][J][K][L] += ((R_actual - R_previo) / R_previo)
            # Verifico que la nueva solución sea mejor que la mejor solución anterior, sino, me quedo con la solución mejor.
            if R_previo >= R_actual:
                P = P_previo
        else:
            lim_cump = "S"
            # A una solución que no satisfaga la factibilidad le asigno la penalidad
            Q[I][J][K][L] += -100
            P = P_previo

        corrida = [j] + [R_previo] + [R_actual] + [rabbits_previo] + [rabbits_actual] + P_previo + [fac[I]] + [fac[J]] + [fac[K]] + [fac[L]] + P + [policy] + [lim_cump]
        data_acum.append(corrida)

data_acum = pd.DataFrame(data_acum, columns=['Episodio', 'R_actual', 'R_previo', 'rabbits_previo', 'rabbits_acutal', 'P1_p', 'P2_p', 'P3_p', 'P4_p', 'A1', 'A2', 'A3', 'A4', 'P1_a', 'P2_a', 'P3_a', 'P4_a', 'Policy', 'cumple_lim'])

data_acum.to_csv('datos_egreedy_lotka_volterra.csv')

sns.scatterplot(y='R_actual', x='P1_p', data=data_acum)

# Impresion de los resultados finales
print("Parametros finales = ", P)
lotka_volterra_instance = LotkaVolterraModel(*P)
print("Recompensa final =", lotka_volterra_instance.simulate())

# Generacion de graficos
# x axis values
x = list(range(0, Runs + 1))
# Grilla y ejes
plt.grid(True)
plt.title('Optimización de modelo DS con K-Armed Bandid algoritmo')
plt.xlabel('Iteraciones del método')
plt.ylabel('Valor variable objetivo')
plt.figure(figsize=(10, 6))
plt.text(481, 50, f'Soluciones: inicial= {round(y[0],2)}, final = {round(y[Runs-1],2)}')
plt.text(481, 45, f'% Ganancia = {round((y[Runs-1] - y[0]) / y[0], 2)}')
# plotting the points
plt.plot(x, y)
# function to show the plot
plt.show()

"""# **Upper Confidence Bound**"""

# Se importa el modelo de Lotka Volterra
#from LotkaVolterra_JSJ import LotkaVolterraModel
# Importar librería para la media
from tkinter import Y
# Se importa paquete matematico numpy
import numpy as np
# Importamos librería genera números aleatorios
import random
# Importamos la libreria de graficas
import matplotlib.pyplot as plt

###para contador de iteraciones
import seaborn as sns
import pandas as pd

# Programación de funciones a usar

# Función para verificar si se violan los rangos de factibilidad de los parámetros a optimizar
def Cumple_Limites(p, l):

    suma = [0]*len(p)

    # Si algún parámetro se sale de los límites se devuelve verdadero
    for i in range(len(p)):

        if p[i] < l[i][0] or p[i] > l[i][1]:
            suma[i]=1

    if sum(suma) > 0:
        return False
    else:
        return True

# Inicio del algoritmo K-Armed bandid para optimizar parámetros del modelo de dinámica de sistemas

E = 0.1 # Parametro de exploracion
fac = [-0.1, -0.05, -0.01, 0, 0.01, 0.05, 0.1] # Posibles cambios que pueden tenre los parámetros
P = [0.002, 0.04, 0.1, 0.0025] # Valor inicial de los parametros
Lim = [[0.0015,0.0025],[0.03,0.05],[0.05,0.15],[0.002,0.003]] # Rango de factibilidad de los parámetros
A = len(fac) # Número de acciones posibles
Q = np.zeros((A,A,A,A)) # Definición de la matriz Q del método K-Armed Bandid
Dim = Q.ndim # Dimensiones
Runs = 3000 # Corridas

lotka_volterra_instance = LotkaVolterraModel(*P)
R_inicial, rabbit_inicial = lotka_volterra_instance.simulate() # Solución inicial del modelo de dinámica de sistemas

# Impresión de parámetros iniciales y solución inicial
print("Parametros iniciales = ", P)
print("Recompensa inicial =", round(R_inicial,5))
print("Rabbits inicial =", round(rabbit_inicial,5))
# Creacion de vector para graficar el retorno
y = [0]
y[0] = R_inicial

# Proceso de explorar - explotar
corrida=[]
data_acum=[]

n_episodios = 1

for j in range(n_episodios):

    P = [0.002, 0.04, 0.1, 0.0025] # Valor inicial de los parametros
    Lim = [[0.0015,0.0025],[0.03,0.05],[0.05,0.15],[0.002,0.003]] # Rango de factibilidad de los parámetros
    A = len(fac) # Número de acciones posibles
    Q = np.zeros((A, A, A, A))

    # PARÁMETROS DE UCB
    c = 2 # Parámetro que controla la exploración
    Nt = np.ones((A, A, A, A))                                                                                          # SE ASUME QUE INICIALMENTE TODAS LAS OPCIONES SE HAN ELEGIDO UNA VEZ

    Dim = Q.ndim # Dimensiones
    Runs = 2400 # Corridas

    for i in range(Runs):

        P_previo = list(P) # Guardo el valor de P previo
        lotka_volterra_instance = LotkaVolterraModel(*P_previo)
        R_previo, rabbits_previo = lotka_volterra_instance.simulate()

        # Se grafica las ganancias
        y.append(R_previo)

        UCB = Q + c * np.sqrt(np.log(i + 1) / (Nt))                                                                     # ABORDAR LA DIVISIÓN POR CERO (ALGUNA OTRA OPCIÓN)

        # Opcion explotar
        max_val = np.amax(UCB) # Identifico el máximo valor
        result = np.where(UCB == max_val) # Encuentro la posición del máximo valor
        I, J, K, L = [result[i][0] for i in range(Dim)] # Guardo la posición del máximo valor
        UCB[result] = Q[result] + c * np.sqrt(np.log(i + 1) / (Nt[result]))                                             # Actualiza el valor del UCB
        Nt[result] += 1 #Actualiza el número de veces que se selecciona

        # Asigno un nuevo P de acuerdo a la posición elegida
        P[0] = P[0] * (1+fac[I])
        P[1] = P[1] * (1+fac[J])
        P[2] = P[2] * (1+fac[K])
        P[3] = P[3] * (1+fac[L])

        # Verifico que esta nueva solución P no viole los límites de factibilidad
        if Cumple_Limites(P, Lim) == True:
            lim_cump = "N"
            # Si sí es una solución factible calculo su recompensa y guardo esta posición
            lotka_volterra_instance = LotkaVolterraModel(*P)
            R_actual, rabbits_actual = lotka_volterra_instance.simulate()

            Q[I][J][K][L] += ((R_actual - R_previo) / R_previo)
            # Verifico que la nueva solución sea mejor que la mejor solución anterior, sino, me quedo con la solución mejor.
            if R_previo >= R_actual:
                P = P_previo
        else:
            lim_cump = "S"
            # A una solución que no satisfaga la factibilidad le asigno la penalidad
            Q[I][J][K][L] += -100
            P = P_previo

        corrida = [j] + [R_previo] + [R_actual] + [rabbits_previo] + [rabbits_actual] + P_previo + [fac[I]] + [fac[J]] + [fac[K]] + [fac[L]] + P + [policy] + [lim_cump]
        data_acum.append(corrida)

data_acum = pd.DataFrame(data_acum, columns=['Episodio', 'R_actual', 'R_previo', 'rabbits_previo', 'rabbits_acutal', 'P1_p', 'P2_p', 'P3_p', 'P4_p', 'A1', 'A2', 'A3', 'A4', 'P1_a', 'P2_a', 'P3_a', 'P4_a', 'Policy', 'cumple_lim'])

data_acum.to_csv('datos_egreedy_lotka_volterra.csv')

sns.scatterplot(y='R_actual', x='P1_p', data=data_acum)

# Impresion de los resultados finales
print("Parametros finales = ", P)
lotka_volterra_instance = LotkaVolterraModel(*P)
print("Recompensa final =", lotka_volterra_instance.simulate())

# Generacion de graficos
# x axis values
x = list(range(0, Runs + 1))
# Grilla y ejes
plt.grid(True)
plt.title('Optimización de modelo DS con K-Armed Bandid algoritmo')
plt.xlabel('Iteraciones del método')
plt.ylabel('Valor variable objetivo')
plt.figure(figsize=(10, 6))
plt.text(481, 50, f'Soluciones: inicial= {round(y[0],2)}, final = {round(y[Runs-1],2)}')
plt.text(481, 45, f'% Ganancia = {round((y[Runs-1] - y[0]) / y[0], 2)}')
# plotting the points
plt.plot(x, y)
# function to show the plot
plt.show()